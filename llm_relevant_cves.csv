cveid,brief
CVE-2023-38896,"An issue in the Langchain component allows remote code execution through specific functions, impacting the security of LLM applications.   This vulnerability affects the `from_math_prompt` and `from_colored_object_prompt` functions, enabling attackers to execute arbitrary code as noted in the description."
CVE-2023-38860,"An issue in LangChain v.0.0.231 allows arbitrary code execution via the prompt parameter.   This vulnerability is highly relevant to LLMs as it can directly affect the prompt processing component, demonstrating a method for attackers to execute code through manipulated input.  "
CVE-2023-23382,"Azure Machine Learning has a vulnerability related to storing sensitive information in an insecure manner, specifically under CWE-257.   This is relevant because it could lead to unauthorized access to sensitive model data, impacting LLM utilization in Azure."
CVE-2023-34094,"ChuanhuChatGPT is vulnerable to unauthorized access to the configuration file, allowing potential theft of sensitive API keys.   This vulnerability exposes sensitive information (""config.json file"") when authentication is not configured, which could lead to unauthorized data access."
CVE-2023-39660,"An issue in the pandasai library allows a remote attacker to execute arbitrary code via a crafted request to the prompt function.   This vulnerability concerns a LLM-relevant component, specifically the ""prompt function,"" which is crucial for model interactions, indicating potential for exploitation in LLM-based applications."
CVE-2023-34541,"Langchain 0.0.171 is vulnerable to arbitrary code execution in the `load_prompt` component.   This vulnerability is significant as it impacts a specific component used in large language models for generating prompts, potentially leading to unauthorized code execution, as indicated by the description in the CVE record."
CVE-2023-33979,"The vulnerability in gpt_academic's Configuration File Handler allows unauthorized access to sensitive information by reading files through the `/file` route.   This exposure is particularly dangerous since ""no sensitive files are configured to be off-limits,"" leading to potential leakage of confidential information.  "
CVE-2023-36095,"An issue in the LangChain library allows arbitrary code execution via Python exec calls, particularly affecting the PALChain component.   This vulnerability is highly relevant to LLMs as it involves code execution related to prompt processing, which can directly impact the integrity and security of LLM-based applications. "
CVE-2023-37275,"System logs in Auto-GPT can be spoofed using ANSI control sequences, potentially misleading users about operational status.   This vulnerability allows external malicious actors to print misleading messages during the model's output, undermining user trust and system integrity."
CVE-2023-35625,"The vulnerability CVE-2023-35625 involves an information disclosure within the Azure Machine Learning SDK, which could expose sensitive information to unauthorized users.   This vulnerability is significant in LLM contexts due to the sensitive nature of data processed in machine learning applications, as highlighted by ""Exposure of Sensitive Information to an Unauthorized Actor."""
CVE-2023-31036,"The vulnerability affects the NVIDIA Triton Inference Server, which is used for deploying machine learning inference models.   The attack could allow for relative path traversal that leads to code execution and data tampering, highlighting its impact on LLM services."
CVE-2023-2885,"Improper enforcement of message integrity during transmission in CBOT Chatbot allows for an Adversary in the Middle (AiTM) attack.   This vulnerability affects communication integrity, making it relevant to LLMs that rely on secure messaging for data integrity during inference operations."
CVE-2023-29374,"In LangChain through 0.0.131, the LLMMathChain chain is susceptible to prompt injection attacks that can execute arbitrary code via the Python exec method.   This highlights a critical vulnerability in the prompt handling of an LLM-related system that could lead to unauthorized command execution, as indicated by ""allows prompt injection attacks."""
CVE-2023-37274,"Auto-GPT, an application leveraging the GPT-4 language model, is vulnerable to a path traversal attack that allows arbitrary code execution due to improper sanitization of user input.   This is pertinent to LLMs because it feeds malicious code back into the system, undermining the integrity of the model's execution environment."
CVE-2023-2800,"Insecure temporary file vulnerability in the Hugging Face Transformers library versions prior to 4.30.0 exposes the system to potential availability issues.   This vulnerability, labeled CWE-377, can lead to high availability impact due to insecure file management in a widely used LLM component, impacting model operation and integrity."
CVE-2023-25664,"TensorFlow experiences a heap buffer overflow vulnerable in the TAvgPoolGrad component prior to version 2.11.1, which could lead to potential exploitation.   This is relevant as TensorFlow is a foundational library for many LLMs, and the vulnerability could affect any LLM utilizing this version, as it indicates a high severity buffer overflow with a CVSS score of 7.5."
CVE-2023-25661,"The vulnerability in TensorFlow versions prior to 2.11.1 allows a malicious input to crash a model using the `Convolution3DTranspose` function, potentially leading to a denial of service.   This is relevant to LLMs as TensorFlow is commonly used to develop and deploy machine learning models in cloud services, and a denial of service could disrupt these applications.  "
CVE-2023-33976,"TensorFlow experiences a segmentation fault in the `array_ops.upper_bound` function when provided with an incorrect input tensor, specifically when not given a rank 2 tensor.   This vulnerability affects the functionality of TensorFlow, which is critical for machine learning applications. "
CVE-2023-36281,"An issue in LangChain version 0.0.171 allows a remote attacker to execute arbitrary code via a JSON file in the load_prompt mechanism, relating to subclasses or a template.   This vulnerability is significant as it can lead directly to code injection attacks on systems reliant on LangChain, evidenced by the description highlighting ""arbitrary code via a JSON file."""
CVE-2023-28858,"Redis-py versions prior to 4.5.3 have a vulnerability where an async Redis command can leave a connection open, potentially enabling data leakage to unrelated requests.   This affects systems utilizing Redis for async operations, particularly in applications like ChatGPT, where such leakage can compromise user data, as noted in the initial reports about this CVE.  "
CVE-2023-32786,"In Langchain through version 0.0.155, a vulnerability allows for prompt injection, leading to potential Server-Side Request Forgery (SSRF) and content injection.   This affects LLM prompting contexts where arbitrary URL access can compromise data integrity, as highlighted by the description of the vulnerability."
CVE-2023-0405,"The vulnerability CVE-2023-0405 in the GPT AI Power plugin allows logged-in users to modify arbitrary posts without proper authorization checks.   This indicates a lack of nonce or privilege checks essential for content safety within AI-related applications, revealing systemic flaws in user authorization mechanisms.  "
CVE-2023-37273,"The vulnerability CVE-2023-37273 involves code injection in the Auto-GPT application due to improper configuration in the docker-compose.yml file.   This allows potential attackers to execute malicious code that could overwrite critical files and gain control over the host system, demonstrating a significant security flaw in how LLM applications handle their deployment configurations.  "
CVE-2023-30444,"IBM Watson Machine Learning on Cloud Pak for Data versions 4.0 and 4.5 are vulnerable to server-side request forgery (SSRF), which could allow an authenticated attacker to send unauthorized requests.   This vulnerability is relevant because it affects a machine learning platform, potentially allowing attackers to exploit the system to facilitate further attacks or leak sensitive information."
CVE-2023-2580,"The vulnerability CVE-2023-2580 affects the AI Engine plugin for WordPress, specifically versions prior to 1.6.83, allowing for Stored XSS attacks.   This issue stems from insufficient sanitization of user settings, enabling high-privilege users to inject malicious scripts into the chatbot system, as stated in the description: ""does not sanitize and escape some of its settings"".  "
CVE-2023-34239,"Gradio, an open-source Python library for building machine learning interfaces, has a vulnerability related to improper input validation due to unfiltered paths, impacting its file access controls.   This system vulnerability is significant as it allows unauthorized file access and potential manipulation, which could compromise the integrity of user interactions with LLM-based applications relying on Gradio."
CVE-2023-25823,"Gradio, an essential Python library for building machine learning demos, contains a vulnerability that exposes hard-coded credentials for its share links, allowing unauthorized access to user demos.   This is critical because it allows users to potentially access sensitive information through shared Gradio applications, as evident from the description stating, ""a private SSH key is sent to any user that connects.""  "
CVE-2023-25668,"TensorFlow is vulnerable to heap out-of-buffer read in its QuantizeAndDequantize operation, potentially leading to remote code execution on affected versions.   This vulnerability is crucial for LLMs because TensorFlow is widely used for building and deploying large language models, as indicated by ""TensorFlow is an open source platform for machine learning."""
CVE-2023-39662,"An issue in the LlamaIndex package allows remote code execution through the `exec` parameter in the PandasQueryEngine function.   This attack targets an LLM-specific component, which can compromise system integrity as it involves executing arbitrary code remotely.  "
CVE-2023-2887,"Authentication Bypass by Spoofing vulnerability in CBOT Chatbot allows an unauthorized user to bypass authentication, specifically affecting versions before Core: v4.0.3.4 and Panel: v4.0.3.7.   This vulnerability is significant as it can compromise the security of the chatbot system, enabling unauthorized access to sensitive functionalities, indicated by the CVSS score of 9.8."
CVE-2023-3686,"A vulnerability in Bylancer QuickAI OpenAI 3.8.1 allows SQL injection through the GET Parameter Handler of the /blog component.   This poses a critical risk as ""The manipulation of the argument s leads to sql injection,"" indicating potential data breaches or unauthorized access."
CVE-2023-4897,"Relative Path Traversal vulnerability in the mintplex-labs/anything-llm system prior to version 0.0.1 can lead to unauthorized file access.   This vulnerability could allow attackers to exploit the system's file management, as evidenced by the CWE-23 classification of the issue.  "
CVE-2023-4899,"SQL Injection vulnerability in the ""mintplex-labs/anything-llm"" GitHub repository affects versions prior to 0.0.1.   This vulnerability can be exploited to bypass protections and gain unauthorized access to sensitive data, pinpointing the risks associated with LLM frameworks that interface with databases."
CVE-2023-4898,"Authentication Bypass vulnerability in the `mintplex-labs/anything-llm` system allows unauthorized access due to weak authentication measures.   This is critical for LLMs as it potentially exposes sensitive data and model access; ""confidentialityImpact"": ""HIGH"".  "
CVE-2023-49785,"NextChat, a chat interface for ChatGPT, is vulnerable to Server-Side Request Forgery (SSRF) and Cross-Site Scripting (XSS), affecting versions 2.11.2 and prior.   This vulnerability enables high confidentiality and integrity impact, allowing attackers to interact with internal resources and mask their source IP."
CVE-2023-46248,"The vulnerability allows an attacker to control the `.vscode/cody.json` configuration file for the Cody AI coding assistant, leading to possible Remote Code Execution (RCE) on the user's machine.   This is relevant as it affects an AI tool aimed at assisting with coding tasks, enabling attackers to exploit its functionality and execute arbitrary code."
CVE-2023-6730,"Deserialization of untrusted data vulnerability exists in the ""huggingface/transformers"" library prior to version 4.36.   This is crucial for LLMs as it impacts the safety and integrity of model inference and data handling; ""Deserialization of Untrusted Data"".  "
CVE-2023-7018,"Deserialization of untrusted data vulnerability in the huggingface/transformers library prior to version 4.36 allows for potential exploitation.   This is relevant as it affects a widely used LLM component, potentially leading to high impacts on availability, confidentiality, and integrity."
CVE-2023-5212,"The AI ChatBot plugin for WordPress is vulnerable to Arbitrary File Deletion, which allows authenticated attackers with subscriber privileges to delete arbitrary files on the server.   This vulnerability impacts the AI ChatBot component, suggesting risks to LLM-related functionalities, particularly given the context of its AI integration."
CVE-2023-48741,"Improper Neutralization of Special Elements used in an SQL Command ('SQL Injection') vulnerability in the QuantumCloud AI ChatBot affects versions up to 4.7.8.   This vulnerability, classified as SQL Injection (CWE-89), can compromise the confidentiality of sensitive data within the chatbot system, indicating it is a significant concern for LLM applications.  "
CVE-2024-0088,NVIDIA Triton Inference Server has a vulnerability in its shared memory APIs that could lead to denial of service and data tampering.   This is relevant as it directly affects a system (NVIDIA Triton Inference Server) critical for LLM inference capabilities.  
CVE-2023-5832,"Improper input validation in the mintplex-labs/anything-llm project could allow attackers to affect the integrity of LLM systems using this component.   The vulnerability demonstrates a risk where improper handling of user input can lead to potentially harmful consequences, specifically due to ""CWE-20 Improper Input Validation."""
CVE-2024-0435,"User can exploit a self-XSS vulnerability in the ""anything-llm"" framework when sending messages.   This attack relies on the chat application's handling of user input, enabling execution of malicious scripts in the user's own browser context."
CVE-2024-0100,"NVIDIA Triton Inference Server is vulnerable in its tracing API, allowing system file corruption, potentially leading to denial of service and data tampering.   This vulnerability impacts an LLM-relevant system because Triton is commonly used for serving LLMs and other AI models, thus affecting their operational integrity."
CVE-2023-7215,"A vulnerability in Chanzhaoyu's chatgpt-web application version 2.11.1 allows for cross-site scripting (XSS) through the manipulation of input arguments.   This issue is relevant as it can potentially compromise the security of web-based LLM interfaces, with the input example ""<image src onerror=prompt(document.domain)>"" showcasing exploitation methods."
CVE-2023-51409,"Unrestricted file upload vulnerability in the AI Engine: ChatGPT Chatbot plugin for WordPress allows attackers to upload dangerous file types.   This vulnerability affects the integration of AI with web platforms, as it can lead to exploitation of AI functionalities, particularly in outdated versions."
CVE-2024-0452,"The AI ChatBot for WordPress is vulnerable to unauthorized data modification due to missing capability checks in the openai_file_upload_callback function.   This allows authenticated attackers to upload files to a linked OpenAI account, potentially compromising sensitive data interactions.  "
CVE-2024-0440,"The vulnerability allows attackers to perform Server-Side Request Forgery (SSRF) on the ""anything-llm"" system, enabling unauthorized access to sensitive host files.   This is relevant to LLMs as it exposes the potential for data leakage, with the description noting ""introspect host files"" which could lead to compromised system integrity."
CVE-2023-28312,"The vulnerability CVE-2023-28312 pertains to the Azure Machine Learning platform, specifically an information disclosure issue due to improper access control (CWE-284).   This is significant for LLMs as Azure Machine Learning is a common provider for deploying models; it highlights potential access issues where sensitive model information might be exposed.  "
CVE-2024-0378,"The AI Engine plugin for WordPress is vulnerable to Stored Cross-Site Scripting due to insufficient input sanitization and output escaping.   This vulnerability could allow unauthenticated attackers to inject arbitrary web scripts that execute in user sessions, affecting the plugin's integrity as it works with LLM-based features like chatbots.  "
CVE-2024-0087,"NVIDIA Triton Inference Server has a vulnerability that allows a user to set the logging location to an arbitrary file, potentially leading to critical security issues.   This is LLM-relevant as Triton is often used for serving models, and the vulnerability may allow code execution and do significant harm, as indicated by the description stating ""leads to code execution, denial of service""."
CVE-2023-45063,"Cross-Site Request Forgery (CSRF) vulnerability in the ReCorp AI Content Writing Assistant plugin impacts versions <= 1.1.5.   This vulnerability could exploit user interactions due to the low attack complexity, affecting the integrity of content generated by AI systems like GPT-3 and GPT-4."
CVE-2023-51527,"Exposure of Sensitive Information to an Unauthorized Actor vulnerability affects the ""AI Power: Complete AI Pack – Powered by GPT-4"" plugin, specifically in versions up to and including 1.8.2.   This issue pertains to the handling of sensitive data in a plugin related to a GPT-4 powered system, indicating that unauthorized actors may gain access to sensitive information—""Sensitivity Information"" was highlighted in the CVE."
CVE-2023-5833,"Improper access control in the ""mintplex-labs/anything-llm"" GitHub repository allows unauthorized access to certain functionalities of the LLM system before version 0.1.0.   This vulnerability is relevant as it pertains to a specific LLM product, affecting its security and confidentiality with a CVSS score of 8.1, indicating high severity."
CVE-2023-5241,"The AI ChatBot for WordPress has a Directory Traversal vulnerability that allows attackers to manipulate files on the server, potentially causing Denial of Service (DoS).   This is relevant because it affects an AI component in WordPress that likely uses LLMs for chat functionality, as evidenced by ""AI ChatBot"" and ""OpenAI""."
CVE-2023-51528,"Cross-Site Request Forgery (CSRF) vulnerability in the AI Power: Complete AI Pack powered by GPT-4 affects versions up to 1.8.12.   This vulnerability could potentially allow unauthorized actions to be executed on behalf of a user, posing risks to the integrity of interactions within the plugin."
CVE-2024-0103,"NVIDIA Triton Inference Server has a vulnerability that allows for incorrect initialization of resources due to a network issue, leading to information disclosure.   This affects LLM operations, as Triton is used for serving models, and the disclosure could compromise sensitive training data or model parameters."
CVE-2024-0436,"The vulnerability allows attackers to brute-force the password for the ""anything-llm"" system via a timing attack, which can compromise password security.   The system involved is an LLM product, and the flaw is based on the linear comparison used for password verification, indicating a potential for high confidentiality impact."
CVE-2024-0095,"The NVIDIA Triton Inference Server, which facilitates model inference in LLMs, is vulnerable to log injection, potentially allowing attackers to execute arbitrary commands.   This vulnerability affects system integrity as it can lead to code execution, privilege escalation, and data tampering, highlighting a significant security risk for LLM-based applications."
CVE-2024-0404,"A mass assignment vulnerability exists in the `/api/invite/:code` endpoint of the mintplex-labs/anything-llm repository, allowing unauthorized creation of high-privileged accounts.   This vulnerability affects the LLM system's user management component, enabling attackers to gain administrative access through unauthorized account roles."
CVE-2024-0550,"A privileged user can exploit a relative path traversal vulnerability to access arbitrary system files through the frontend API of the LLM product ""anything-llm.""   This is relevant because it highlights a security flaw that enables unauthorized access to sensitive data, indicating a breach of confidentiality and integrity in the system."
CVE-2024-0453,"The AI ChatBot for WordPress (WPBot) is susceptible to unauthorized file deletions from a linked OpenAI account due to inadequate capability checks on the `openai_file_delete_callback` function across all versions up to 5.3.4.   This indicates a failure in authorization controls specifically affecting LLM interactions, as noted in the description mentioning ""unauthorized modification of data"" and ""linked OpenAI account"".  "
CVE-2024-0763,"Any user can delete arbitrary folders on a remote server in the ""anything-llm"" system due to improper validation of parameters.   This vulnerability suggests that the system's input sanitization process is flawed, allowing for a path traversal attack."
CVE-2024-11394,"Hugging Face Transformers contains a vulnerability that allows remote code execution due to improper validation of deserialized model files.   This is relevant to LLMs because it directly affects the functionality and security of the Hugging Face Transformers library, which is widely used for creating language models."
CVE-2024-0549,"mintplex-labs/anything-llm is vulnerable to a relative path traversal attack, compromising data integrity and availability by allowing unauthorized file deletion.   This affects the LLM component by potentially removing critical database files, as stated: ""allowing unauthorized attackers...to delete files and folders""."
CVE-2024-0699,"The AI Engine plugin for WordPress is vulnerable to arbitrary file uploads due to missing file type validation, allowing authenticated attackers to potentially execute remote code.   This is relevant as it impacts LLM-specific components used in chatbots and assistants, evidenced by the description stating vulnerabilities exist in ""Chatbots, Generators, Assistants, GPT 4 and more!""  "
CVE-2024-12471,"The vulnerability in the Post Saint plugin for WordPress allows for arbitrary file uploads due to a lack of proper authorization and file type validation.   This poses a risk for systems utilizing LLMs by enabling remote code execution, as indicated by ""arbitrary files uploads due to a missing capability check."""
CVE-2024-1522,A Cross-Site Request Forgery (CSRF) vulnerability in the parisneo/lollms-webui project allows remote attackers to execute arbitrary code.   This vulnerability targets the `/execute_code` API endpoint and enables unauthorized execution of OS commands via crafted malicious web pages.
CVE-2024-0798,"A privilege escalation vulnerability in the mintplex-labs/anything-llm system allows users with the 'default' role to delete documents uploaded by 'admin'.   This vulnerability indicates a flaw in access control that can lead to significant data integrity issues, as stated: ""an attacker can exploit this vulnerability by sending a crafted DELETE request."""
CVE-2024-11392,"Hugging Face Transformers has a vulnerability in its MobileViTV2 component that allows for deserialization of untrusted data, potentially leading to remote code execution.   This is relevant to LLMs because it affects the transformer framework used in many LLM applications, allowing attackers to execute arbitrary code through user interaction with malicious files or pages."
CVE-2024-10131,"The `add_llm` function in the `llm_app.py` file of the infiniflow/ragflow application contains a remote code execution (RCE) vulnerability due to improper input validation.   The vulnerability arises specifically from allowing dynamic class instantiation based on user-provided input for `llm_factory`, which can lead to executing arbitrary code, as indicated by the description mentioning ""execute arbitrary code.""  "
CVE-2024-13059,"A vulnerability in the mintplex-labs/anything-llm system prior to version 1.3.1 allows for path traversal due to improper handling of non-ASCII filenames.   This could lead to arbitrary file write and remote code execution, impacting the integrity and confidentiality of the LLM system."
CVE-2024-11393,"Hugging Face Transformers MaskFormer model contains a vulnerability allowing remote code execution due to deserialization of untrusted data.   This is relevant as it directly affects the LLM component of Hugging Face, allowing attackers to exploit model file parsing, ""resulting in deserialization of untrusted data."""
CVE-2024-12606,"The AI Scribe plugin for WordPress has a vulnerability that allows authenticated attackers to modify plugin settings due to a missing authorization check.   This is relevant to LLMs as it affects a plugin utilizing ChatGPT and similar models, thus exposing system integrity."
CVE-2024-12473,"The AI Scribe WordPress plugin, which integrates LLM capabilities, is vulnerable to SQL Injection due to insufficient escaping on the 'template_id' parameter.   This vulnerability allows authenticated attackers with Contributor-level access to execute arbitrary SQL queries, which can expose sensitive database information."
CVE-2024-1646,"The vulnerability identified as CVE-2024-1646 pertains to authentication bypass in the parisneo/lollms-webui application.   This flaw allows unauthorized access to sensitive endpoints, which can impact the functionality of LLM-related tasks such as updating and controlling recordings.  "
CVE-2024-12236,"A security issue exists in the Vertex Gemini API, allowing data exfiltration due to improper handling of file URIs with VPC Service Controls enabled.   The vulnerability is relevant because it affects a key component of LLM operation, evidenced by phrases like ""data exfiltration"" and ""VPC-SC security perimeter""."
CVE-2024-1511,"The parisneo/lollms-webui is vulnerable to path traversal due to inadequate user-supplied file path validation, allowing unauthorized file access.   This vulnerability permits an attacker to read and execute arbitrary files, as noted in the description mentioning ""unauthenticated attacker"" and ""read, write, and in certain configurations execute arbitrary files""."
CVE-2024-1741,"Improper authorization in lunary-ai/lunary allows unauthorized users to access and manipulate prompt templates using old tokens.   This vulnerability is critical as it allows users to ""read, create, modify, and delete prompt templates,"" potentially compromising sensitive LLM data."
CVE-2024-1520,"An OS Command Injection vulnerability in the '/open_code_folder' endpoint of the parisneo/lollms-webui application allows attackers to execute arbitrary commands on the server.   This is relevant as it affects an LLM-specific application, potentially compromising any sensitive data processed by the model, as indicated by ""unauthorized access, data leakage, or complete system compromise."""
CVE-2024-0451,"The AI ChatBot plugin for WordPress is vulnerable to unauthorized data access due to a missing capability check in the `openai_file_list_callback` function.   This vulnerability allows authenticated attackers with low-level access to list files in a linked OpenAI account, compromising security for LLM systems integrated with this chatbot.  "
CVE-2024-0795,"If an attacker gains admin access, they can create new users with elevated privileges due to a lack of backend authentication.   This is significant because it compromises the security of the LLM system 'anything-llm', allowing unauthorized user creation and control."
CVE-2024-0759,"The vulnerability CVE-2024-0759 affects the AnythingLLM system, allowing an attacker with elevated permissions to perform link-scraping of internal IPs within the same network.   This is LLM-relevant as it involves the AnythingLLM platform which handles potentially sensitive internal data, indicating a significant risk to system confidentiality.  "
CVE-2024-11896,"The Text Prompter plugin for WordPress is vulnerable to Stored Cross-Site Scripting (XSS) due to insufficient input sanitization, allowing authenticated attackers to inject scripts.   This vulnerability poses a risk to applications utilizing LLMs for content generation, particularly in environments where user-generated prompts can be exploited, as indicated by ""text_prompter"" shortcode vulnerabilities."
CVE-2024-0455,"The CVE-2024-0455 vulnerability relates to a Server-Side Request Forgery (SSRF) flaw in AnythingLLM that allows unauthorized users to access EC2 instance credentials.   This could lead to severe security risks as it enables users with minimal privileges to access sensitive information, as stated: ""any user with the proper authorization level... could put in the URL.""  "
CVE-2024-12366,"PandasAI's interactive prompt function is vulnerable to prompt injection, allowing for remote code execution instead of expected natural language processing.   This is significant as it pertains to LLM operations, highlighted by ""prompt injection"" which directly affects how prompts are processed."
CVE-2024-0439,"User permissions can be exploited in the ""anything-llm"" system, allowing a manager to modify restricted configurations via manual HTTP requests.   This vulnerability reflects improper privilege management (CWE-269) as it permits modifications that should be restricted, compromising integrity, with a CVSS score of 7.1 indicating high severity."
CVE-2024-0551,"The vulnerability CVE-2024-0551 involves improper access control in the ""anything-llm"" system, allowing default users to export sensitive database information.   This is critical because it can lead to unauthorized data exposure, as highlighted by the ""confidentialityImpact"": ""HIGH.""  "
CVE-2024-1602,"The stored XSS vulnerability in the parisneo/lollms-webui can lead to Remote Code Execution due to inadequate sanitization of model output data.   This vulnerability is critical as it allows attackers to inject malicious scripts that execute in the user's browser, affecting LLM-specific components that manage user input and output."
CVE-2024-1880,"An OS command injection vulnerability in the MacOS Text-To-Speech class of the significant-gravitas/autogpt project could allow arbitrary code execution.   This is strongly relevant to LLM as it affects the functionality of AutoGPT, a language model application, leveraging the `--speak` feature and relies on user input which can be manipulated to execute shell commands.  "
CVE-2024-1879,"A Cross-Site Request Forgery (CSRF) vulnerability in the AutoGPT system allows attackers to execute arbitrary commands due to inadequate API protections.   This vulnerability directly affects the AutoGPT server's security, allowing crafted requests from malicious sites, indicating a weakness in handling API endpoints."
CVE-2024-21624,"The vulnerability in Nonebot2 relates to a potential information leak through user-constructed message templates, which could expose sensitive information such as environment variables.   This is relevant due to the risk of unauthorized access to sensitive data when developers improperly manage user inputs in templates, as highlighted by ""exposure of sensitive information.""  "
CVE-2024-1569,"The vulnerability in `parisneo/lollms-webui` allows attackers to trigger a denial of service (DoS) by exploiting uncontrolled resource consumption through repeated unauthenticated HTTP POST requests.   This vulnerability is relevant because it affects a web UI for an LLM and can render the system unusable, as indicated by ""uncontrolled resource consumption"" leading to ""exhausting system resources.""  "
CVE-2024-22309,"Deserialization of untrusted data in the ChatBot with AI plugin for WordPress allows for PHP object injection, potentially compromising the integrity and confidentiality of the system.   This vulnerability is relevant because it specifically involves a component—ChatBot with AI—using LLM technology, suggesting that an attacker might manipulate its behavior through malicious data, underscoring the importance of secure coding practices.  "
CVE-2024-21825,"A heap-based buffer overflow vulnerability exists in the GGUF library's parsing functionality in llama.cpp, allowing code execution via a crafted .gguf file.   This shows relevance as it affects the llama.cpp system directly and involves executing code, which is critical for LLM operations."
CVE-2024-1873,"The vulnerability provides a path traversal and denial of service in the `parisneo/lollms-webui` system.   This allows attackers to manipulate file paths, potentially disrupting services and compromising data integrity.  "
CVE-2024-23605,"A heap-based buffer overflow vulnerability in the GGUF library of llama.cpp can allow code execution when a specially crafted .gguf file is processed.   This is relevant because it highlights a critical vulnerability affecting the llama.cpp library, which is integral for LLM functionalities, making it a potential target for attackers."
CVE-2024-2361,"A vulnerability in the parisneo/lollms-webui allows for arbitrary file upload and read due to insufficient sanitization of user input, specifically in the `install_model()` function.   This affects the LLM system by enabling attackers to exploit path traversal vulnerabilities, as noted by the mention of ""arbitrary read and upload capabilities."""
CVE-2024-21552,"All versions of `SuperAGI` have a critical vulnerability that allows for arbitrary code execution due to unsafe use of the `eval` function, which can be exploited to execute attacks on the application server.   This vulnerability is especially relevant to LLMs, as it involves their output being manipulated to execute arbitrary commands, highlighting a lack of sanitization in user inputs.  "
CVE-2024-21802,"A heap-based buffer overflow vulnerability in the GGUF library of llama.cpp can lead to code execution when processing a specially crafted .gguf file.   This vulnerability is critical because it can allow attackers to execute arbitrary code, demonstrating a serious security flaw in an LLM-relevant software component."
CVE-2024-2288,A Cross-Site Request Forgery (CSRF) vulnerability in the profile picture upload functionality of the Lollms application could allow attackers to change user settings without their consent.   This flaw on the Lollms web application could lead to denial of service and potential XSS attacks as it affects core user interactions within the system.
CVE-2024-1881,"AutoGPT, a component of significant-gravitas/autogpt, is vulnerable to OS Command Injection due to improper shell command validation.   This vulnerability allows attackers to exploit the execution of arbitrary commands due to checks only being performed on the first word of the command."
CVE-2024-23751,"The vulnerability in LlamaIndex up to version 0.9.34 allows SQL injection through the Text-to-SQL feature in multiple components.   This is critically relevant since it demonstrates how an LLM-specific functionality, such as querying, can be exploited, potentially leading to the deletion of important data as evidenced by ""Drop the Students table"" within natural language input."
CVE-2024-24566,"Unauthorized access to plugins in the Lobe Chat framework due to improper access control can potentially expose sensitive functionalities to malicious users.   This is relevant to LLMs as it affects a chatbot framework designed for multimodal functionalities, specifically leveraging plugins improperly due to the lack of authentication when the `ACCESS_CODE` is deployed."
CVE-2024-2178,"A path traversal vulnerability exists in the parisneo/lollms-webui that allows unauthorized access to sensitive information by manipulating parameters.   This vulnerability weakens the security of the LLM web interface, allowing attackers to access files outside the intended directory structure leading to potential information leaks."
CVE-2024-23730,"The vulnerability in the LlamaHub plugin loaders allows attackers to execute arbitrary code due to improper handling of YAML files.   This is relevant to LLMs because it affects a component used in deploying models, highlighting risks in the plugin system that supports LLM functionalities.  "
CVE-2024-21799,"The Intel(R) Extension for Transformers software is vulnerable to a path traversal issue prior to version 1.5, which may allow an authenticated user to escalate privileges through local access.   This is significant for LLMs since Intel's extensions are tailored for machine learning tasks, and privilege escalation may compromise the integrity of model inference and execution workflows.  "
CVE-2024-21513,"Versions of the langchain-experimental package are vulnerable to Arbitrary Code Execution due to improper handling of prompt inputs within the VectorSQLDatabaseChain component.   This vulnerability allows an attacker to execute arbitrary Python code by manipulating input prompts, as stated in the description: ""An attacker can exploit this vulnerability and execute arbitrary python code if they can control the input prompt.""  "
CVE-2024-2548,"A path traversal vulnerability in the `parisneo/lollms-webui` application allows unauthorized file access on the Windows system through inadequate path validation.   This vulnerability affects a relevant LLM system, as it specifically compromises the application's security measures, enabling attackers to read sensitive files like `win.ini`."
CVE-2024-2217,"gaizhenbiao/chuanhuchatgpt has an improper access control vulnerability that allows unauthorized access to sensitive information in the `config.json` file, including API keys and user credentials.   This poses a risk to LLM systems as sensitive keys relevant to AI model access could be exposed; ""allowing unauthorized access to the `config.json` file."""
CVE-2024-21836,"A heap-based buffer overflow vulnerability in the GGUF library of llama.cpp can allow code execution via a specially crafted .gguf file.   This is significant as it targets the gguf file processing component of an LLM implementation, highlighting potential exploitation risks."
CVE-2024-2366,"A remote code execution vulnerability exists in the parisneo/lollms-webui application due to insufficient path sanitization, enabling arbitrary code execution.   This vulnerability directly affects the lollms-webui, a system relevant to LLM frameworks, as it allows for executing malicious code which can compromise the integrity and functionality of the LLM application.  "
CVE-2024-2359,The vulnerability CVE-2024-2359 in the parisneo/lollms-webui allows attackers to execute arbitrary code due to improper access control on the `/execute_code` endpoint.   This is LLM-relevant because the affected component is an LLM web user interface that handles execution commands which can directly impact LLM functionality.
CVE-2024-2360,"The CVE-2024-2360 vulnerability in parisneo/lollms-webui allows for path traversal leading to remote code execution due to inadequate sanitization of user input in critical settings.   This relates to LLMs as it affects a web interface potentially used for LLM management and deployment, allowing attackers to execute arbitrary code which could compromise LLM operations."
CVE-2024-23496,"A heap-based buffer overflow vulnerability in the gguf_fread_str functionality of llama.cpp can be exploited by providing a specially crafted .gguf file, potentially leading to code execution.   This is relevant as it impacts the llama.cpp system, an important component in LLM architectures, indicating that malicious inputs could compromise the model's integrity."
CVE-2024-0765,"As a default user on a multi-user instance of AnythingLLM, you could execute a call to the `/export-data` endpoint and exfiltrate sensitive data from the system since the data gets deleted after download.   This is critical due to the sensitivity of the data and the potential for unauthorized access, evidenced by the high CVSS score of 9.6 indicating confidentiality impact."
CVE-2024-27564,"A Server-Side Request Forgery (SSRF) vulnerability in the ChatGPT component pictureproxy.php allows arbitrary remote requests via URL injection.   This vulnerability is relevant to LLM systems because it could exploit the underlying infrastructure that supports LLM functionality, demonstrating potential security flaws such as allowing attackers to perform unauthorized actions."
CVE-2024-10100,"A path traversal vulnerability exists in the binary-husky/gpt_academic system due to improper handling of file parameters, allowing potential access to sensitive files.   This is relevant to LLMs as it compromises the security of a system designed for academic purposes involving GPT models, highlighting the risk of exposing sensitive application files.  "
CVE-2024-2624,"A path traversal and arbitrary file upload vulnerability has been identified in the parisneo/lollms-webui application, impacting its security protocols.   This vulnerability allows attackers to exploit insufficient input sanitization at specific endpoints, leading to potential leakage of sensitive information and unauthorized access. "
CVE-2024-3029,"In mintplex-labs/anything-llm, improper input validation allows an attacker to exploit a specific endpoint to delete all users and disable multi-user functionality.   This vulnerability is critical as it leads to unauthorized access and control, evidenced by phrases like ""deletes all users"" and ""create a new admin user without requiring a password."""
CVE-2024-29100,"The vulnerability CVE-2024-29100 in the AI Engine: ChatGPT Chatbot plugin allows for unrestricted uploads of potentially dangerous files.   This can lead to severe security risks, as file uploads could be leveraged to execute malicious code or compromise the system, as indicated by the description of ""Unrestricted Upload of File with Dangerous Type""."
CVE-2024-28224,"Ollama has a DNS rebinding vulnerability that enables unauthorized users to access its API, allowing potential interactions with large language models.   This is relevant to LLMs because it directly impacts the application's ability to securely manage interactions with the models, as it states users can ""chat with a large language model,"" which signifies exploitation in the context of LLM operations.  "
CVE-2024-25639,"The vulnerability in Khoj's application enables Cross-Site Scripting (XSS) through improper sanitization of AI model responses and user inputs, affecting both Desktop and Web clients.      This is relevant to LLMs because it involves ""Prompt Injection"" that can compromise responses generated by AI, demonstrating how unsafe user inputs can manipulate outputs, as indicated by ""inadequately sanitize the AI model's response.""  "
CVE-2024-2913,"A race condition vulnerability in the mintplex-labs/anything-llm system allows attackers to create unauthorized user accounts by exploiting the user invite acceptance process.   This vulnerability is critical because it enables multiple accounts from a single invite link, thus compromising system integrity; the advisory states, ""Attackers can exploit this vulnerability by sending multiple concurrent requests.""  "
CVE-2024-27565,"A Server-Side Request Forgery (SSRF) vulnerability in the weixin.php component of ChatGPT-wechat-personal allows attackers to force the application to make arbitrary requests.   This is relevant because SSRF vulnerabilities can lead to unrestricted access to internal resources, highlighting potential security flaws in LLM integration with other systems.  "
CVE-2024-3104,"A remote code execution vulnerability exists in the mintplex-labs/anything-llm system due to improper handling of environment variables.   This vulnerability allows attackers to inject arbitrary environment variables via the `POST /api/system/update-env` endpoint, enabling arbitrary code execution."
CVE-2024-3025,"mintplex-labs/anything-llm is vulnerable to path traversal attacks, allowing unauthorized access to sensitive files through manipulated logo filenames.   This vulnerability highlights a serious security flaw where ""insufficient validation of user-supplied input in the logo filename functionality"" can be exploited."
CVE-2024-3126,A command injection vulnerability in the 'run_xtts_api_server' function of the parisneo/lollms-webui allows remote code execution through unsanitized user input.   This vulnerability is significant because it can lead to arbitrary code execution on systems running the LLM web application.
CVE-2024-3028,"Improper input validation in the mintplex-labs/anything-llm component allows attackers to read and delete arbitrary files on the server.   This is relevant to LLMs as it targets the system running LLM applications, which could lead to unauthorized access to sensitive data stored in associated files like '.env'."
CVE-2024-31224,"The vulnerability identified as CVE-2024-31224 in GPT Academic involves the deserialization of untrustworthy data, which can lead to remote code execution when interacting with large language models.   This vulnerability highlights critical security risks in the LLM's backend services, allowing attackers to exploit the deserialization flaw via network interactions.  "
CVE-2024-3098,"A vulnerability in the `llama_index` package's `exec_utils` class allows for prompt injection, leading to arbitrary code execution within LLM systems.   This attack targets the inference component by exploiting insufficient input validation, as highlighted in the description: ""prompt injection leading to arbitrary code execution.""  "
CVE-2024-2952,"BerriAI/litellm is vulnerable to Server-Side Template Injection, allowing attackers to execute arbitrary code on the server through the `/completions` endpoint.   This vulnerability is particularly concerning as it involves LLM components, evidenced by ""the `hf_chat_template` method processing the `chat_template` parameter""."
CVE-2024-30256,"Open WebUI, a user-friendly interface for LLMs, is vulnerable to authenticated blind server-side request forgery (SSRF), which could potentially expose sensitive information or lead to unauthorized actions.   This vulnerability poses risks to LLM operations as it allows for deceptive requests to be made from the server, impacting the integrity of interactions—highlighted by its classification under CWE-918."
CVE-2024-3110,"A stored XSS vulnerability exists in the mintplex-labs/anything-llm application that can allow an attacker to take over an admin account by executing malicious JavaScript code.   This is highly relevant to LLM systems as it affects the application's integrity and potential misuse of LLM-generated content, highlighted by ""steal the admin's authorization token."""
CVE-2024-22422,"The vulnerability in ""AnythingLLM"" allows an unauthenticated denial of service attack via a poorly handled public API endpoint, leading to server crashes.   The ""data-export"" endpoint can be exploited due to insufficient error handling and lacks authentication, allowing attackers to crash the server with a single packet, indicating high availability impact with a CVSS score of 7.5.  "
CVE-2024-3102,"A JSON Injection vulnerability in the `mintplex-labs/anything-llm` application allows for brute force attacks targeting the username parameter during login.   This vulnerability is significant as it compromises the authentication process on an LLM-specific system, enabling attackers to ascertain full usernames through improper handling of input values.  "
CVE-2024-29090,"Server-Side Request Forgery (SSRF) vulnerability in the Jordy Meow AI Engine: ChatGPT Chatbot affects versions up to 2.1.4.   This vulnerability indicates that it can lead to significant security issues within the context of AI-integrated applications, as noted by the phrase ""Server-Side Request Forgery (SSRF)""."
CVE-2024-3101,"The vulnerability in mintplex-labs/anything-llm permits an attacker to escalate privileges by deactivating 'Multi-User Mode' through improper input validation, leading to potential unauthorized access.   This is relevant as it affects a system associated with LLMs and allows unauthorized administrative access, evidenced by ""deactivate 'Multi-User Mode'"" and the resulting creation of a new admin user."
CVE-2024-3150,"In mintplex-labs/anything-llm, a privilege escalation vulnerability allows users to gain administrator access through improper input validation in the thread update process.   This affects user roles within the system, enabling attackers to perform all actions due to the ""improper input validation when handling HTTP POST requests."""
CVE-2024-28088,"LangChain through version 0.1.10 is vulnerable to a path traversal attack that can lead to the disclosure of an API key for an LLM online service or even remote code execution.   This vulnerability allows an attacker to manipulate the path in a load_chain call, thus bypassing intended configuration loading behaviors, as highlighted in the description referencing “directory traversal” and risks related to API key exposure."
CVE-2024-3152,"mintplex-labs' anything-llm has vulnerabilities due to improper input validation in critical endpoints, allowing privilege escalation and unauthorized file access.   This is relevant because it highlights security flaws in an LLM application that could lead to severe impacts, evidenced by ""multiple security issues due to improper input validation""."
CVE-2024-2358,"A path traversal vulnerability in the '/apply_settings' endpoint of parisneo/lollms-webui allows attackers to execute arbitrary code due to insufficient input sanitization.   The vulnerability specifically affects a web interface used for LLM settings management, posing critical security risks (CVSS score 9.8).  "
CVE-2024-3033,"An improper authorization vulnerability in the mintplex-labs/anything-llm application allows unauthenticated users to execute destructive actions on the VectorDB.   This poses a risk to LLM systems as it can lead to data loss of document embeddings, affecting the functionality of chat workspaces and widgets."
CVE-2024-0116,"NVIDIA Triton Inference Server has a vulnerability that allows for an out-of-bounds read by releasing a shared memory region while it is in use, potentially leading to a denial of service.   This is relevant because Triton Inference Server is a key component in deploying machine learning models and can be targeted to disrupt inference services, as indicated by the mention of ""denial of service"".  "
CVE-2024-31451,"DocsGPT, a GPT-powered chat for documentation, has a vulnerability allowing unauthenticated limited file write due to a path traversal issue in routes.py.   This flaw can potentially compromise the integrity of the DocsGPT system, indicating how access control failures may lead to unexpected behaviors in LLM applications."
CVE-2024-3279,"An improper access control vulnerability in the mintplex-labs/anything-llm application allows unauthorized manipulation of the `anythingllm.db` database.   This is critical as it allows an attacker to import a database file without authentication, leading to potential data spoofing or deletion."
CVE-2024-3153,"Uncontrolled resource consumption in the mintplex-labs/anything-llm system allows for denial of service (DoS) by manipulating file upload requests.   This vulnerability highlights the risk of unsanitized input handling leading to service disruptions, making it critical for LLM-related systems."
CVE-2024-3271,"A command injection vulnerability in the run-llama/llama_index repository impacts the LLM system by allowing remote code execution via arbitrary inputs.   This vulnerability affects a critical component of the LLM's operational environment, enabling attack vectors that can compromise server security."
CVE-2024-3149,"A Server-Side Request Forgery (SSRF) vulnerability has been identified in the upload link feature of the mintplex-labs/anything-llm system.   This vulnerability allows an attacker to exploit the internal Collector API, leading to unauthorized actions such as arbitrary file deletion."
CVE-2024-3303,"An issue in GitLab allows for improper neutralization of input used for LLM prompting, leading to potential data exfiltration.   This vulnerability shows how prompt injection can compromise sensitive information from within GitLab, highlighting the need for strict input validation.  "
CVE-2024-3403,"The vulnerability in imartinez/privategpt version 0.2.0 allows local file inclusion, enabling attackers to read arbitrary files from the filesystem via the 'Search in Docs' feature.   This directly affects the security of LLM applications, as it can expose sensitive information and facilitate further attacks."
CVE-2024-3404,"In gaizhenbiao/chuanhuchatgpt version 20240121, there exists an improper access control vulnerability that allows authenticated users to access other users' chat history files.   This flaw poses a significant risk to sensitive information, as it allows a potential breach of user privacy through unauthorized access to chat histories."
CVE-2024-34359,"llama-cpp-python is vulnerable to Remote Code Execution due to Server-Side Template Injection in its model metadata processing.   The `jinja2` template is rendered without proper sandboxing, enabling attackers to execute arbitrary code via crafted metadata payloads."
CVE-2024-32965,"An unauthorized SSRF vulnerability in the lobe-chat framework allows attackers to send malicious requests that can access internal network services, potentially leaking sensitive data.   This is relevant to LLMs because 'Lobe Chat' is an AI chat framework that likely utilizes LLMs for its functionality, and compromising its security can lead to sensitive information leakage related to AI operations."
CVE-2024-3429,A path traversal vulnerability in the parisneo/lollms application allows unauthorized file reading due to insufficient input sanitization in specific functions.   This is critical for LLMs as it enables attackers to access sensitive files potentially affecting the model's integrity and data confidentiality.  
CVE-2024-3283,"A vulnerability in the mintplex-labs/anything-llm system allows users to escalate their privileges from manager to admin through an improperly authorized API endpoint.   This is relevant as it affects the overall system security of an LLM, evidenced by ""improperly authorizes manager-level users."""
CVE-2024-32878,"Llama.cpp, a component for LLM inference in C/C++, has a vulnerability due to the use of an uninitialized heap variable which can lead to DOS and potential RCE.   This vulnerability is critical as it affects the inference capabilities of an LLM system and may allow attackers to exploit memory issues."
CVE-2024-32964,"Lobe Chat's `/api/proxy` endpoint contains an unauthorized Server-Side Request Forgery (SSRF) vulnerability allowing attackers to access intranet services and leak sensitive information without authentication.   This vulnerability is particularly relevant to LLMs due to its potential to manipulate data flows within a chatbot infrastructure, impacting the integrity and confidentiality of responses (""can cause Server-Side Request Forgery"").  "
CVE-2024-35198,"TorchServe, a tool for serving PyTorch models, has a vulnerability that allows the bypass of the allowed_urls security configuration.   This could lead to unauthorized model downloads by leveraging incorrect URL resolution, as stated: ""check on allowed_urls configuration can be by-passed if the URL contains characters such as '...'."""
CVE-2024-3322,"A path traversal vulnerability exists in the 'cyber_security/codeguard' component of the parisneo/lollms-webui, allowing attackers to read and overwrite arbitrary files.   This flaw in the 'process_folder' function allows an attacker to specify arbitrary paths, potentially leading to sensitive information disclosure.  "
CVE-2024-31462,"The vulnerability in Stable Diffusion's web UI allows for limited file write access, primarily affecting configuration settings on Windows systems.   This indicates a potential security flaw in the system's handling of user input through the `create_ui` method, enabling unauthorized file writes."
CVE-2024-37146,"Flowise, a tool for building workflows for large language models, has a reflected cross-site scripting (XSS) vulnerability in its `/api/v1/credentials/id` endpoint which could be exploited to execute arbitrary scripts.   This vulnerability is particularly concerning because it could allow attackers to run JavaScript in user sessions, potentially leading to data theft or unauthorized redirection."
CVE-2024-34440,"The CVE-2024-34440 vulnerability allows for unrestricted file uploads in the AI Engine: ChatGPT Chatbot plugin for WordPress versions up to 2.2.63.   This issue could potentially allow attackers to upload malicious files, which poses risks to the underlying system since it is specifically tied to an LLM-related chatbot application."
CVE-2024-35199,"The vulnerability allows unauthorized access to gRPC ports of TorchServe, potentially exposing critical model serving capabilities.   High CVSS scores indicate serious availability impact, making it a significant concern for systems deploying PyTorch models."
CVE-2024-3166,"A Cross-Site Scripting (XSS) vulnerability in the mintplex-labs/anything-llm application could lead to the execution of arbitrary JavaScript code, affecting both desktop and web versions.   This vulnerability can escalate to Remote Code Execution due to insecure settings in Electron, indicating a significant risk for users interacting with the system."
CVE-2024-3121,"A remote code execution vulnerability exists in the create_conda_env function of the parisneo/lollms repository, version 5.9.0, due to improper use of subprocess calls.   This is relevant to LLMs as the vulnerability directly affects the lollms system, which is likely used in LLM-related tasks, enabling execution of arbitrary commands."
CVE-2024-3435,"A path traversal vulnerability in the 'save_settings' endpoint of the parisneo/lollms-webui allows attackers to manipulate application configurations.   This is relevant to LLM as it could lead to remote code execution, compromising the LLM model's integrity through unauthorized access.  "
CVE-2024-34073,"The vulnerability in the sagemaker-python-sdk allows OS Command Injection due to improper handling of the ""requirements_path"" parameter in the capture_dependencies function.   This flaw can lead to remote code execution and affects the confidentiality and integrity of the system, as stated in the CVE description mentioning ""potentially unsafe Operating System (OS) Command Injection."""
CVE-2024-34072,"The CVE-2024-34072 vulnerability in the sagemaker-python-sdk enables deserialization of untrusted data, which can lead to remote code execution.   This is particularly relevant because it affects the training and deployment of machine learning models, systems critical to the functionality of large language models.  "
CVE-2024-3570,"A stored Cross-Site Scripting (XSS) vulnerability in the chat functionality of the mintplex-labs/anything-llm allows attackers to execute malicious scripts within user sessions.   The vulnerability arises from improper input sanitization using `dangerouslySetInnerHTML`, making it susceptible to script injection."
CVE-2024-36421,"The vulnerability in Flowise, identified as CVE-2024-36421, results from a CORS misconfiguration that allows arbitrary origins to access the server, potentially leading to information theft.   This is relevant to LLMs because Flowise is a platform specifically designed to build customized LLM flows, and the misconfiguration may expose sensitive user data."
CVE-2024-3568,"The CVE-2024-3568 vulnerability in the huggingface/transformers library allows for arbitrary code execution through deserialization during model loading.   This vulnerability directly impacts the LLM framework by exploiting the `load_repo_checkpoint()` function, potentially allowing attackers to execute malicious code during the model training process."
CVE-2024-37465,"Improper Neutralization of Input During Web Page Generation (XSS) vulnerability in the GPT3 AI Content Writer plugin for WordPress allows stored XSS attacks.   This vulnerability is relevant because it affects a plugin leveraging AI technology; as mentioned, it ""allows Stored XSS"" targeting the GPT3 AI Content Writer."
CVE-2024-37032,"Ollama versions prior to 0.1.34 fail to properly validate the format of the model digest, resulting in potential issues with model path handling.   This vulnerability could allow unintended model path access or command execution due to mishandled input, affecting security in LLM deployments."
CVE-2024-3569,"A Denial of Service (DoS) vulnerability in the mintplex-labs/anything-llm application can severely impact the system when it operates in 'just me' mode with a password.   This is highly relevant to LLM systems as it affects availability, with a CVSS base score of 7.5 indicating significant impact on resource consumption.  "
CVE-2024-38791,"Server-Side Request Forgery (SSRF) vulnerability in the AI Engine: ChatGPT Chatbot affects versions up to 2.4.7.   This vulnerability allows attackers to potentially exploit the chatbot system to send unauthorized requests, impacting its security functionality."
CVE-2024-37145,"In version 1.4.3 of the Flowise system, a reflected cross-site scripting (XSS) vulnerability allows attackers to inject JavaScript into user sessions through a crafted URL.   This poses risks as attackers can steal information and manipulate user sessions, with evidence mentioning ""allowing the attacker to steal sensitive information.""  "
CVE-2024-37895,"The vulnerability involves the exposure of sensitive information, specifically the API key in the lobe-chat framework for LLMs/AI chat systems.   This API key leak could allow unauthorized actors to perform actions that compromise the system's integrity since it directly affects an LLM-specific component.  "
CVE-2024-39720,"An issue in Ollama versions before 0.1.46 allows attackers to exploit malformed GGUF files leading to application crashes.   This vulnerability is critical as it affects the Ollama application which is likely used for managing and deploying LLMs, demonstrating a risk in model management."
CVE-2024-36422,"In version 1.4.3 of Flowise, a reflected cross-site scripting (XSS) vulnerability occurs in the `api/v1/chatflows/id` endpoint, potentially allowing an attacker to inject malicious scripts.   This vulnerability is particularly concerning for LLM applications since it may enable attackers to exploit user sessions and access sensitive information by manipulating JavaScript in the context of LLM-driven workflows.  "
CVE-2024-36423,"In version 1.4.3 of the Flowise platform, a reflected cross-site scripting (XSS) vulnerability exists in the `/api/v1/public-chatflows/id` endpoint, allowing attackers to inject JavaScript into user sessions.   This affects the LLM interface by enabling malicious actors to steal sensitive information and perform unauthorized actions within the user's session, indicating the potential exploitation of LLM-integrated functionality."
CVE-2024-4151,"An Improper Access Control vulnerability in the `lunary-ai/lunary` system allows unauthorized users to access and modify prompts due to insufficient access checks in PATCH and GET requests.   This vulnerability could lead to significant data integrity and confidentiality issues, as the description states ""users can view and update any prompts in any projects.""  "
CVE-2024-37902,"The vulnerability in DeepJavaLibrary (DJL) allows path traversal due to inadequate restrictions on file paths, potentially leading to overwriting system files.   This is highly relevant to LLMs as DJL is utilized in large model inference, which can be compromised if unauthorized files are processed."
CVE-2024-39686,"Bert-VITS2's `bert_gen` function is vulnerable to OS command injection due to improper handling of user input.   This vulnerability allows arbitrary command execution, impacting both confidentiality and integrity, as specified in ""CWE-78: Improper Neutralization of Special Elements used in an OS Command""."
CVE-2024-39688,"The vulnerability CVE-2024-39688 in the Bert-VITS2 system allows for improper file writes due to a path traversal issue in the `generate_config` function.   This affects the LLM component by potentially enabling unauthorized access or manipulation of configuration files, as evidenced by “writing /config/config.json file in arbitrary directory on the server.”"
CVE-2024-38514,"There is a critical Server-Side Request Forgery (SSRF) vulnerability in the NextChat system, which lacks validation of the `endpoint` parameter, allowing attackers to send arbitrary requests and potentially execute JavaScript code in user browsers.   This is highly relevant as it affects a system that works as an interface for interacting with LLMs, specifically targeting its API vulnerabilities, highlighted by the severity rating of CVSS 7.4.  "
CVE-2024-3851,"A stored Cross-Site Scripting (XSS) vulnerability exists in the 'imartinez/privategpt' repository due to improper validation of file uploads.   This vulnerability is significant as it allows attackers to upload malicious HTML files that execute arbitrary JavaScript code in a user's browser session, potentially leading to phishing."
CVE-2024-40594,"The OpenAI ChatGPT app for macOS prior to July 2024 stores user conversations in cleartext, violating data confidentiality.   This vulnerability poses a risk to user privacy, as the app's implementation results in sensitive conversation data being accessible to other applications in an unencrypted format."
CVE-2024-42479,"The vulnerability in `llama.cpp` allows for arbitrary address writing through an unsafe use of the `data` pointer in the `rpc_tensor` structure, affecting LLM inference operations.   This is strongly relevant to LLMs as it compromises the integrity of the inference process, as indicated by ""arbitrary address writing"" which can lead to severe consequences."
CVE-2024-4078,"A vulnerability in the parisneo/lollms allows for arbitrary code execution due to insufficient sanitization of user input, specifically in the `/unInstall_binding` endpoint.   This impacts the deployment of LLM systems, raising serious concerns as it enables remote code execution, evidenced by the CVSS score of 9.8 indicating critical severity."
CVE-2024-4084,"A Server-Side Request Forgery (SSRF) vulnerability in the mintplex-labs/anything-llm component allows attackers to circumvent security measures designed to restrict internal network access.   This SSRF flaw stems from insufficient validation of user-supplied URLs, which could facilitate unauthorized access to internal assets."
CVE-2024-41130,"The vulnerability in llama.cpp involves a null pointer dereference in the gguf_init_from_file function, which affects LLM inference capabilities.   This is relevant because it compromises a fundamental component of the llama.cpp system used for LLM inference, stating ""prior to b3427, llama.cpp contains a null pointer dereference."""
CVE-2024-38206,"Microsoft Copilot Studio is vulnerable to a Server-Side Request Forgery (SSRF) attack that could allow an authenticated attacker to leak sensitive information.   This vulnerability is relevant to LLMs as it affects a system designed for LLM operations, as indicated by the title ""Microsoft Copilot Studio Information Disclosure Vulnerability""."
CVE-2024-39685,"The vulnerability in the Bert-VITS2 model involves a command injection flaw in the `webui_preprocess.py` file's `resample` function, allowing arbitrary command execution through user-supplied input.   This is critical as it can lead to unauthorized system actions: ""User input supplied to the data_dir variable is used directly in a command executed with subprocess.run(cmd, shell=True)."""
CVE-2024-3924,"The vulnerability CVE-2024-3924 involves a code injection flaw in the huggingface/text-generation-inference system, specifically within the `autodocs.yml` workflow.   This flaw stems from the insecure handling of the `github.head_ref` input, allowing attackers to execute arbitrary code within the GitHub Actions runner.  "
CVE-2024-3402,"A stored Cross-Site Scripting (XSS) vulnerability in the gaizhenbiao/chuanhuchatgpt application allows for the execution of malicious JavaScript code in user browsers.   This is relevant to LLMs as it pertains to the security of a chatbot application leveraging model output, leading to potential browser hijacking."
CVE-2024-42478,"llama.cpp, a library providing LLM inference capabilities, is vulnerable to an out-of-bounds read due to an unsafe pointer in its rpc_tensor structure, allowing arbitrary address access.   This vulnerability affects LLM systems that utilize llama.cpp, as detailed in the description stating, ""The unsafe `data` pointer member... can cause arbitrary address reading."""
CVE-2024-42477,"The vulnerability in the `llama.cpp` system is a global buffer overflow in the `rpc_tensor` structure, which could potentially lead to memory data leakage.   This is relevant as it impacts the underlying system providing LLM inference capabilities, specifically the `llama.cpp` product."
CVE-2024-4284,"A vulnerability in the ""anything-llm"" system from mintplex-labs allows for a denial of service (DoS) condition through improper user ID handling, leading to inaccessible accounts.   This issue affects the LLM system's availability, showcasing the consequence of ""uncontrolled resource consumption.""  "
CVE-2024-4181,"A command injection vulnerability exists in the RunGptLLM class of the llama_index library, allowing arbitrary command execution on client machines.   This vulnerability is relevant to LLMs as it targets a specific component (llama_index) used to connect with Language Learning Models and poses a risk of full control over clients' systems."
CVE-2024-4267,"A remote code execution (RCE) vulnerability exists within the 'open_file' module of the parisneo/lollms-webui due to improper command neutralization.   This vulnerability is LLM-relevant as it involves executing arbitrary commands via user data in the LLM web interface, potentially compromising the system."
CVE-2024-4264,A remote code execution (RCE) vulnerability exists in the `berriai/litellm` project due to unsafe usage of the `eval` function within the `litellm.get_secret()` method.   This is highly relevant as it allows attackers to manipulate the behavior of a language model system by injecting malicious code through environment variables.
CVE-2024-4320,"A remote code execution (RCE) vulnerability in the `/install_extension` endpoint of the parisneo/lollms-webui application can allow attackers to execute arbitrary code.   This vulnerability can be exploited without user interaction, making it particularly dangerous for systems exposed to external networks."
CVE-2024-4286,"Mintplex-Labs' anything-llm application suffers from improper neutralization of special elements in expression language statements, potentially leading to severe data manipulation.   This vulnerability can be exploited to modify user database attributes without proper checks, impacting the integrity of user interactions with the LLM.  "
CVE-2024-4322,"A path traversal vulnerability in the parisneo/lollms-webui application allows attackers to manipulate the `category` parameter within the `/list_personalities` endpoint, leading to potential information disclosure.   This is relevant since the system may inadvertently expose user-sensitive information through improper input validation."
CVE-2024-4099,"An AI feature in GitLab was found to improperly handle unsanitized content, allowing for prompt injection attacks.   This vulnerability is directly connected to LLMs because it implicates an AI feature that processes inputs without adequate sanitization, as evidenced by ""An AI feature was found to read unsanitized content.""  "
CVE-2024-4498,"A Path Traversal and RFI vulnerability in the parisneo/lollms-webui allows attackers to manipulate file system paths, leading to Remote Code Execution.   This issue is relevant as it targets a component of an LLM interface, allowing attackers potential unauthorized access and code execution through the web UI (""discuss_db_name"" parameter)."
CVE-2024-4499,"A Cross-Site Request Forgery (CSRF) vulnerability exists in the XTTS server of parisneo/lollms version 9.6 due to a lax CORS policy, allowing unauthorized API requests.   This vulnerability is relevant because it affects an LLM-related component, specifically the XTTS server used in text-to-speech functionalities."
CVE-2024-4343,"A Python command injection vulnerability in imartinez/privategpt allows attackers to execute arbitrary commands through the `complete()` method, compromising the system's integrity.   The use of `eval()` to parse strings from an AWS SageMaker LLM endpoint creates a critical security flaw, enabling potential exploitations."
CVE-2024-4321,"A Local File Inclusion (LFI) vulnerability in the gaizhenbiao/chuanhuchatgpt application allows attackers to exploit improper input validation in file path handling.   This is particularly relevant to LLM systems since it involves the management of chat history, which could expose sensitive information related to model interactions, as stated, ""read sensitive files on the server, leading to information leakage."""
CVE-2024-4315,"The vulnerability CVE-2024-4315 involves a Local File Inclusion (LFI) issue in the parisneo/lollms system due to insufficient path sanitization, compromising Windows systems.   This is relevant to LLMs as it targets the lollms framework, which is utilized for running language models and could lead to unauthorized file access or deletion, impacting system stability.  "
CVE-2024-4287,"In the mintplex-labs/anything-llm system, improper input validation allows unauthorized creation of Administrator accounts.   This vulnerability is classified as ""CWE-20 Improper Input Validation"" and has a high confidentiality and integrity impact."
CVE-2024-41950,"Haystack, an end-to-end LLM framework, is vulnerable to remote code execution due to insecure Jinja2 templates which allow arbitrary code execution if rendered improperly.   This vulnerability is pertinent as it relates to the LLM framework directly used in application development and execution, as described in the advisory: ""if anyone can create and render that template on the client machine they run any code.""  "
CVE-2024-43610,"The vulnerability in Microsoft Copilot Studio allows an unauthorized actor to access sensitive information through network attacks.   This is relevant because it exposes data in an LLM-related environment, indicating potential risks connected to unattended interactions in AI-assisted applications.  "
CVE-2024-36420,The Flowise system's `/api/v1/openai-assistants-file` endpoint is vulnerable to arbitrary file read due to insufficient sanitization of the `fileName` parameter.   This indicates a security flaw that could expose sensitive information or enable further exploitation.  
CVE-2024-4520,"An improper access control vulnerability in the gaizhenbiao/chuanhuchatgpt application allows users to access others' chat histories without interaction.   The breach of confidentiality could lead to significant data leaks due to ""insufficient access control mechanisms"" in handling chat history data."
CVE-2024-42679,"SQL Injection vulnerability in the 'litellm' component of the Super easy enterprise management system allows local attackers to execute arbitrary code.   This issue directly impacts the LLM implementation (litellm) and is categorized as a type C relevance, as it suggests exploitation methods and evaluation of vulnerabilities in LLM systems."
CVE-2024-4328,"A Cross-Site Request Forgery (CSRF) vulnerability in the `clear_personality_files_list` function of the `parisneo/lollms-webui` can lead to unauthorized actions such as deleting files.   This vulnerability specifically targets a component of the LLM system and allows attackers to exploit poor request handling, stating ""the vulnerability arises from the use of a GET request to clear personality files list.""  "
CVE-2024-4403,"A Cross-Site Request Forgery (CSRF) vulnerability exists in the `restart_program` function of the `parisneo/lollms-webui`, which can lead to unintended actions like program resets.   This vulnerability is relevant as it impacts the functionality and security of a system designed for LLM interaction, as seen through the phrase ""affects the installation process.""  "
CVE-2024-4560,"The Kognetiks Chatbot for WordPress is vulnerable to arbitrary file uploads, allowing unauthenticated attackers to upload files to the server, which could lead to remote code execution.   This vulnerability affects the chatbot system's file upload functionality, highlighting the risk posed by missing file type validation in the `chatbot_chatgpt_upload_file_to_assistant` function."
CVE-2024-46946,"The vulnerability concerns LangChain Experimental's LLMSymbolicMathChain allowing arbitrary code execution due to improper input validation in the sympy.sympify function.   This is relevant to LLMs because it directly affects a component used in LLMs for symbolic math, potentially impacting model behavior and security."
CVE-2024-48139,"A prompt injection vulnerability in the chatbox of Blackbox AI v1.3.95 enables attackers to exfiltrate chat data between users and the AI assistant through crafted messages.   This vulnerability directly relates to how LLMs handle prompts, as it allows unauthorized access to sensitive user interactions, demonstrating potential risks in prompt handling techniques."
CVE-2024-45201,An issue in the `llama_index` package prior to version 0.10.38 allows for code injection via an exec call in the `download/integration.py` file.   The vulnerability is relevant to LLMs as it relates to code execution which could compromise the stability and security of LLM-integrating systems.
CVE-2024-45989,"Monica AI Assistant desktop application v2.3.0 is vulnerable to exposure of sensitive information through a prompt injection, which may allow unauthorized access to user chat data.   This is significant because it specifically relates to the use of prompts in an AI context: ""A prompt injection allows an attacker to modify chatbot answer."""
CVE-2024-4326,"The vulnerability in the parisneo/lollms-webui allows remote code execution through improperly secured endpoints.   This crucial flaw lets attackers execute arbitrary code by leveraging the `/apply_settings` and `/execute_code` endpoints, indicating high risk to LLM-related functionality.  "
CVE-2024-46489,"A remote command execution (RCE) vulnerability in the promptr version 6.0.7 allows attackers to execute arbitrary commands via a crafted URL.   This type is relevant because the vulnerability affects a component related to LLM prompting, with the description noting ""arbitrary commands"" could be executed through manipulated inputs."
CVE-2024-48140,"A prompt injection vulnerability in the chatbox of ""Monica Your AI Copilot"" allows attackers to exfiltrate chat data.   This vulnerability is significant as it compromises the confidentiality of user interactions with the AI assistant, evidenced by ""access and exfiltrate all previous and subsequent chat data."""
CVE-2024-48145,"A prompt injection vulnerability in the chatbox of Netangular Technologies ChatNet AI allows for the exfiltration of sensitive chat data via a crafted message.   This type of vulnerability directly impacts LLMs by compromising the confidentiality of user interactions, indicating a high severity with ""CVSS base score: 9.1""."
CVE-2024-49038,"Improper neutralization of input during web page generation in Microsoft Copilot Studio can allow an unauthorized attacker to escalate privileges over a network.   This vulnerability is relevant to LLMs as Copilot Studio is a tool used for generating AI-driven content and services, highlighting security risks in AI environments.  "
CVE-2024-4841,"A Path Traversal vulnerability exists in the parisneo/lollms-webui that can lead to unauthorized access to sensitive files on the victim's system.   This vulnerability is significant as it arises from the improper handling of the 'path' parameter in HTTP requests, allowing an attacker to exploit it: ""an attacker can predict the folders, subfolders, and files present on the victim's computer."""
CVE-2024-48144,"A prompt injection vulnerability in the chatbox of the Fusion Chat AI Assistant allows attackers to exfiltrate chat data via crafted messages.   This vulnerability directly affects an AI assistant's functionality, showcasing risks inherent in user prompts and AI interactions.  "
CVE-2024-48142,"A prompt injection vulnerability in the Butterfly Effect Limited Monica ChatGPT AI Assistant v2.4.0 allows attackers to access and exfiltrate all previous and subsequent chat data via a crafted message.   This is relevant to LLM systems as it directly affects the chat component, enabling unauthorized data access, highlighting ""prompt injection"" and ""exfiltrate all previous and subsequent chat data.""  "
CVE-2024-47868,"Several components in Gradio, an open-source Python package for prototyping, are vulnerable to arbitrary file leaks due to post-process data validation issues.   The exposure arises when attackers bypass input constraints to access sensitive files, particularly through components returning file data, as noted in the advisory's detailed description.  "
CVE-2024-4890,"A blind SQL injection vulnerability in the berriai/litellm application can lead to unauthorized access to sensitive information.   This is relevant to LLM systems as it exploits a specific component within the application that processes user data, emphasizing the risks associated with improper parameter handling."
CVE-2024-49375,"A vulnerability in Rasa allows remote code execution via malicious model loading, posing significant risks to systems using this LLM framework.   This is especially relevant for LLMs as Rasa is an open-source machine learning framework designed to handle natural language processing tasks, linking it closely to LLM functionalities."
CVE-2024-4889,"A code injection vulnerability exists in the `berriai/litellm` application due to unvalidated input leading to arbitrary code execution.   This vulnerability is notable as it allows attackers to exploit the eval function, raising concerns in LLM systems due to malicious code execution potential."
CVE-2024-4839,"A Cross-Site Request Forgery (CSRF) vulnerability exists in the 'Servers Configurations' function of the parisneo/lollms-webui, affecting various services including XTTS and vLLM.   This vulnerability allows attackers to trick users into inadvertently installing malicious services by submitting unauthorized requests, demonstrating its critical impact on LLM-related functionalities."
CVE-2024-4888,"BerriAI's litellm experiences a critical vulnerability that allows arbitrary file deletion via improper input validation on an endpoint, endangering critical files.   This is significant for LLMs as it can lead to unauthorized deletion of vital components or configurations necessary for LLM operation, evidenced by the phrase ""deleting critical files on the server."""
CVE-2024-50050,"Llama Stack prior to revision 7a8aa775e5a267cf8660d83140011a0b7f91e005 used pickle for socket communication, which could lead to remote code execution.   This is relevant because it involves a serialization vulnerability that could compromise the LLM system's integrity (""Deserialization of Untrusted Data"")."
CVE-2024-5126,"An improper access control vulnerability exists in the lunary-ai/lunary system that allows unauthorized users to update prompt details.   This vulnerability is highly relevant to LLM systems as it affects the prompt updating functionality, a critical component for prompt integrity."
CVE-2024-5184,"The EmailGPT service exhibits a prompt injection vulnerability that allows malicious users to manipulate the service logic through injected prompts.   This system's vulnerability can lead to significant privacy and security concerns, as attackers can exploit it to gain delivery of sensitive hard-coded prompts or execute harmful requests."
CVE-2024-5125,"The vulnerability allows for Cross-Site Scripting (XSS) and Open Redirect in the parisneo/lollms-webui, affecting its input validation for SVG file uploads.   This is relevant to LLMs as it can compromise the integrity of the AI module’s functionality that processes these user-uploaded files, citing ""malicious JavaScript code"" as a risk.  "
CVE-2024-5208,"An uncontrolled resource consumption vulnerability exists in the `upload-link` endpoint of mintplex-labs/anything-llm, leading to a potential denial of service (DoS).   This highlights a weakness in the platform's server management, as invalid requests can cause shutdowns, indicating oversight in previous fixes.  "
CVE-2024-5216,"The vulnerability in mintplex-labs/anything-llm leads to a Denial of Service (DoS) condition caused by uncontrolled resource consumption due to oversized usernames.   This undermines the system's security posture and operational functionality, as it prevents administrators from managing users effectively."
CVE-2024-53844,"The CVE-2024-53844 vulnerability in the EDDI (Enhanced Dialog Driven Interface) middleware allows for path traversal, potentially exposing sensitive files within the application context.   This is strongly relevant as EDDI manages LLM API bots, and the flaw allows unauthorized access through manipulated requests, as indicated by ""manipulating the `botFilename` parameter."""
CVE-2024-48141,"A prompt injection vulnerability in Zhipu AI CodeGeeX v2.17.0 allows attackers to access and exfiltrate chat data via crafted messages.   This is significant as it directly affects the interaction component of the LLM, making the LLM-leveraging system susceptible to data breaches."
CVE-2024-5185,"The EmbedAI application is vulnerable to data poisoning attacks due to a CSRF vulnerability, affecting the integrity of its language model.   This vulnerability arises from ""the absence of a secure session management implementation and weak CORS policies,"" allowing an attacker to manipulate model input."
CVE-2024-48919,"Cursor is a code editor that allows users to generate terminal commands, but a prompt injection vulnerability enables attackers to execute arbitrary commands in the user's terminal if they import malicious content.   This issue involves ""CWE-20: Improper Input Validation"" and demonstrates how an attacker can leverage user actions in a language model context, specifically through the Terminal Cmd-K feature."
CVE-2024-5211,"A path traversal vulnerability in the mintplex-labs/anything-llm system allows unauthorized reading, deletion, and overwriting of critical files, potentially leading to application compromise.   The vulnerability arises from improper validation of user input and can be exploited through the custom logo setting feature, which jeopardizes application integrity."
CVE-2024-53526,"The vulnerability CVE-2024-53526 allows for Command Execution in the Composio LLM plugins (OpenAI, Claude, Julep) via the handle_tool_calls function.   This is strongly relevant to LLM systems as it can lead to unauthorized execution of commands in integrated LLM environments, compromising their security. "
CVE-2024-5186,"A Server-Side Request Forgery (SSRF) vulnerability in the file upload section of the imartinez/privategpt application allows attackers to send crafted requests, potentially exposing sensitive data over the local network.   This vulnerability is relevant to LLMs as it affects a tool designed for private GPT applications, which may lead to unauthorized access to internal services."
CVE-2024-52384,"Unrestricted Upload of File with Dangerous Type vulnerability in Sage AI product allows arbitrary file uploads, potentially leading to web shell execution.   This vulnerability directly affects the Sage AI: Chatbots, OpenAI GPT-4 Bulk Articles, Dalle-3 Image Generation system, highlighting significant risks such as ""upload a web shell to a web server."""
CVE-2024-5131,"An Improper Access Control vulnerability in the lunary-ai/lunary repository allows unauthorized users to view prompts across projects by manipulating prompt IDs.   This is relevant to LLMs because prompt confidentiality is critical, and evidence includes ""unauthorized users to view any prompts."""
CVE-2024-52803,"LLama Factory has a critical remote OS command injection vulnerability due to improper handling of user input, allowing execution of arbitrary OS commands on host systems.   This is relevant because it affects the LLama Factory, which is used for fine-tuning large language models, thereby presenting a serious security risk."
CVE-2024-5124,"A timing attack vulnerability exists in the gaizhenbiao/chuanhuchatgpt repository, allowing attackers to exploit timing discrepancies in password comparison logic.   This vulnerability, present in version 20240310, compromises user password security due to exposed timing differences in comparisons.  "
CVE-2024-5389,"In lunary-ai/lunary version 1.2.13, an insufficient granularity of access control vulnerability allows unauthorized users to manipulate dataset prompts.   This impacts LLMs as adjustments to prompts can lead to inconsistent experimental results, highlighted by ""unauthorized modifications to dataset prompts."""
CVE-2024-5616,"A Cross-Site Request Forgery (CSRF) vulnerability in mudler/LocalAI allows attackers to delete installed models without user consent.   This vulnerability affects a system that supports LLMs, evidenced by the potential deletion of models like 'gpt-4-vision-preview'."
CVE-2024-52383,"Missing Authorization vulnerability in the KCT Ai Auto Tool Content Writing Assistant (Gemini Writer, ChatGPT) that can lead to exploiting incorrectly configured access control security levels.   This is relevant because it affects a plugin designed for LLM integration, potentially exposing sensitive functionality when misconfigured."
CVE-2024-53880,"NVIDIA Triton Inference Server has a vulnerability in its model loading API that can lead to a denial of service due to integer overflow caused by overly large model files.   This is relevant as it directly affects the availability of an LLM system, with the potential for high impact indicated by the CVSS score.  "
CVE-2024-5278,"The vulnerability allows unrestricted file uploads in the gaizhenbiao/chuanhuchatgpt application, which can lead to remote code execution (RCE).   This is relevant to LLMs because the application interacts with an AI model, and maliciously uploaded files could exploit the model's inference process, as indicated by ""allowing attackers to upload files with arbitrary extensions."""
CVE-2024-5248,"In lunary-ai/lunary version 1.2.5, there is an improper access control vulnerability in the `GET /v1/users/me/org` endpoint, allowing unauthorized access to user information.   This is relevant to LLMs as it enables unauthorized users to retrieve sensitive data, which can affect the privacy and security of prompt management systems, as stated ""allowing users with the `Prompt Editor` role to access the full list of users.""  "
CVE-2024-5482,"A Server-Side Request Forgery (SSRF) vulnerability exists in the 'add_webpage' endpoint of the parisneo/lollms-webui application, allowing for unauthorized requests.   This vulnerability is critical due to its potential to manipulate business logic and access sensitive data as it lacks adequate validation of user-entered URLs."
CVE-2024-49361,"A potential vulnerability in the ACON library related to improper input validation may lead to arbitrary code execution in machine learning applications.   This vulnerability can be exploited through malicious input data, presenting a significant risk for LLMs that utilize ACON for processing user-generated data."
CVE-2024-5225,"An SQL Injection vulnerability exists in the `berriai/litellm` repository affecting the `/global/spend/logs` endpoint, which could allow unauthorized data access and manipulation.   This issue is particularly relevant to LLMs as it targets a backend component involved in processing user inputs, risking the integrity and confidentiality of data stored and manipulated by the LLM system."
CVE-2024-5443,"The vulnerability CVE-2024-5443 involves a path traversal issue in the `parisneo/lollms` software, potentially leading to remote code execution.   This issue arises from insufficient input sanitization in the `/mount_extension` endpoint, allowing attackers to manipulate parameters to execute arbitrary code.  "
CVE-2024-5213,"In the mintplex-labs/anything-llm system, versions up to and including 1.5.3 expose sensitive user information, including password hashes, in the responses after login and account creation.   This vulnerability compromises user credentials, highlighting the critical need to protect sensitive information, as it states, ""the password hash of a user is returned in the response."""
CVE-2024-5565,"The vulnerability in the Vanna library allows for prompt injection attacks that can result in remote code execution due to improper input handling in its ""ask"" method with visualization enabled.   This is significant for LLMs as it directly targets the prompt mechanism integral to their operation, allowing unauthorized code execution through manipulated queries.  "
CVE-2024-55241,"An issue in deep-diver LLM-As-Chatbot before commit 99c2c03 allows a remote attacker to execute arbitrary code through the modelsbyom.py component.   This is strongly relevant to LLMs as it targets a specific component used in LLM chatbot systems, as indicated by the phrase ""execute arbitrary code.""  "
CVE-2024-5982,"A path traversal vulnerability in the gaizhenbiao/chuanhuchatgpt library allows for arbitrary file uploads and directory creation, leading to potential remote code execution.   This is relevant as it highlights a flaw in an LLM-related application where ""unsanitized input handling"" can compromise security."
CVE-2024-5822,"A Server-Side Request Forgery (SSRF) vulnerability in the upload processing interface of the gaizhenbiao/chuanhuchatgpt system enables attackers to send malicious requests, potentially gaining access to sensitive data.   This is relevant to LLMs as it involves a system that processes user requests and data, which can be utilized in LLM-oriented applications. "
CVE-2024-5751,"BerriAI/litellm's version v1.35.8 is vulnerable to remote code execution due to improper handling of environment variables within the `add_deployment` function.   This is significant as it directly targets the operational integrity of an LLM system, allowing attackers to execute arbitrary code through a crafted payload sent to a specific endpoint."
CVE-2024-5933,"A Cross-site Scripting (XSS) vulnerability exists in the chat functionality of the parisneo/lollms-webui, allowing attackers to inject malicious scripts.   This is relevant to LLMs as the web UI is likely used during user interactions for model prompts, exposing user inputs to potential threats through chat."
CVE-2024-5824,"A path traversal vulnerability in the `/set_personality_config` endpoint of the parisneo/lollms system allows unauthorized modifications to critical configuration files, potentially leading to remote code execution.   This vulnerability demonstrates a direct threat to LLM configurations that could compromise the integrity and security of the model's deployment."
CVE-2024-6281,"A path traversal vulnerability in `parisneo/lollms` allows attackers to manipulate file paths and potentially write to sensitive system folders.   This directly affects LLM components since `lollms` is related to large language models, making its integrity crucial."
CVE-2024-6139,"A path traversal vulnerability in the XTTS server of the parisneo/lollms package allows attackers to write audio files to arbitrary locations, risking unauthorized access to the file system.   This is relevant to LLMs as it affects a component that might be utilized for text-to-speech (TTS) functions in LLM applications, as indicated by ""**path traversal vulnerability**"" in the context of the LLM environment."
CVE-2024-5823,"A file overwrite vulnerability in the `gaizhenbiao/chuanhuchatgpt` application allows unauthorized access to configuration files, affecting system behavior.   This is relevant to LLMs as it impacts a specific application used in the context of chat interfaces, potentially altering outcomes, as the description states it could lead to ""unauthorized changes in system behavior."""
CVE-2024-56137,"MaxKB, an open source knowledge base system utilizing a large language model, has a remote command execution vulnerability that allows privileged users to run OS commands in custom scripts prior to version 1.9.0.   This vulnerability is critical because it impacts privileged functionality in a system designed for knowledge extraction using LLMs."
CVE-2024-56800,"Firecrawl, a web scraper utilized for extracting webpage content for LLMs, is vulnerable to a server-side request forgery (SSRF) attack in versions prior to 1.1.1.   This can be exploited via a malicious site that redirects to a local IP address, potentially leading to unauthorized access of local network resources, which is significant in the context of LLM use cases."
CVE-2024-5710,"berriai/litellm version 1.34.34 is vulnerable to improper access control within its team management functionality, allowing unauthorized actions.   The vulnerability arises from ""insufficient access control checks"" in the system's endpoints, posing a risk to the integrity of team management operations."
CVE-2024-5827,"Vanna v0.3.4 is vulnerable to SQL injection in its DuckDB integration, allowing attackers to write arbitrary files, including potentially harmful scripts, on the server's filesystem.   This issue is particularly relevant to LLMs since these systems often interact with databases and may be susceptible to similar types of prompt injection; as noted, ""malicious SQL training data and generate corresponding queries."""
CVE-2024-6040,"In the parisneo/lollms-webui version v9.8, there is a missing client_id parameter that exposes it to CSRF and local attacks.   This vulnerability allows unauthorized actions on victim machines, as indicated by the description of endpoints being ""susceptible to CSRF attacks."""
CVE-2024-6581,"A vulnerability in the Lollms application allows remote code execution due to stored XSS from improperly handled SVG file uploads.   This is relevant as it affects a web application that could host LLMs, indicated by vulnerabilities arising from the application's discussion image upload functionality."
CVE-2024-6091,"A vulnerability in significant-gravitas/autogpt version 0.5.1 allows an attacker to bypass shell command denylist settings, enabling unauthorized command execution.   This is relevant to LLMs as it directly affects the security of an integrated system that may be using autogpt, potentially leading to leaking sensitive information or manipulation of the model's execution."
CVE-2024-6331,"The vulnerability in the stitionai/devika system allows Local File Read (LFI) via a Prompt Injection attack, resulting in potential exposure of sensitive files.   This is relevant to LLMs as it involves exploitation through direct user input that manipulates the model's behavior, which can lead to significant information leakage."
CVE-2024-6090,"A path traversal vulnerability in gaizhenbiao/chuanhuchatgpt allows users to delete other users' chat histories and JSON files, impacting the system's availability.   This is relevant because it targets a component (chat history management) specific to LLM applications, potentially leading to service denial."
CVE-2024-6036,"The vulnerability in the `gaizhenbiao/chuanhuchatgpt` system allows any user to restart the server by exploiting the `/queue/join?` endpoint.   This can significantly disrupt service availability, as stated: ""This unrestricted server restart capability can severely disrupt service availability."""
CVE-2024-5826,"The vulnerability CVE-2024-5826 in the vanna-ai/vanna system allows for remote code execution due to prompt injection in the `vanna.ask` function.   This indicates a direct risk to the LLM application as it involves a critical flaw that permits attackers to execute arbitrary code, highlighting that ""the lack of a sandbox when executing LLM-generated code"" is the core issue."
CVE-2024-5969,"The vulnerability in the AIomatic content writer allows unauthenticated email sending due to insufficient input validation in the 'aiomatic_send_email' function.   This is relevant as it affects a system designed for AI content generation, potentially misusing LLM capabilities for sending unsolicited emails with arbitrary content."
CVE-2024-5753,"The vulnerability CVE-2024-5753 affects the vanna-ai/vanna system, enabling local file read through SQL injection due to improper input handling in a Python Flask API.   This is relevant because it demonstrates how prompt injection can expose sensitive information from the underlying server, evidenced by the ability to read files like `/etc/passwd`."
CVE-2024-6255,"A vulnerability in the JSON file handling of the gaizhenbiao/chuanhuchatgpt system allows for directory traversal attacks, enabling unauthorized deletion of critical configuration files.   This is relevant to LLMs because the configuration files like `config.json` are essential for properly functioning language models, highlighting the risk of disrupted operations.  "
CVE-2024-6587,"A Server-Side Request Forgery (SSRF) vulnerability in the `berriai/litellm` application could allow attackers to intercept sensitive OpenAI API keys.   This flaw is critical as it can lead to unauthorized access and the potential misuse of API keys, showing high confidentiality impact."
CVE-2024-6674,"A CORS misconfiguration in the `parisneo/lollms-webui` prior to version 10 can lead to sensitive information leaks, including logs and private API keys.   This issue heavily impacts LLM confidentiality due to the nature of the LLM components relying on sensitive user data."
CVE-2024-56363,"The APTRS system has a Server-Side Template Injection (SSTI) vulnerability that allows attackers to execute arbitrary code via unvalidated user input in a Jinja2 template.   This is relevant because it highlights a flaw in a system related to template rendering, specifically involving user input handling which could compromise the integrity and execution of LLM-related functionalities.  "
CVE-2024-6038,"A Regular Expression Denial of Service (ReDoS) vulnerability exists in the `gaizhenbiao/chuanhuchatgpt` system, specifically in the `filter_history` function of `utils.py`, allowing attackers to degrade service performance.   This is relevant to LLMs as it compromises service availability and thus affects any deployment relying on this component for user interactions."
CVE-2024-6845,"The Chatbot with ChatGPT WordPress plugin before version 2.4.6 exposes a REST endpoint lacking proper authorization, allowing potential key leakage.   This vulnerability permits unauthenticated users to retrieve and decode the OpenAI API key, which could be exploited to compromise LLM services."
CVE-2024-6971,"A path traversal vulnerability exists in the parisneo/lollms-webui, allowing local file access control issues.   This impacts the `lollms` component as it permits unauthorized vectorization of files, citing ""does not implement security measures.""  "
CVE-2024-6250,"An absolute path traversal vulnerability in parisneo/lollms-webui allows unauthorized file access on Windows systems through the `open_file` endpoint.   This vulnerability is relevant as it could potentially allow an attacker to exploit the LLM's underlying file handling logic, where files may contain sensitive training data or configurations."
CVE-2024-6847,"The vulnerability CVE-2024-6847 in the ""Chatbot with ChatGPT WordPress"" plugin allows SQL injection due to improper sanitization of user input.   This underscores a critical flaw in the system's input handling that can be exploited by unauthenticated users, as noted in the description ""does not properly sanitise and escape a parameter before using it in a SQL statement."""
CVE-2024-6706,"Attackers can craft a malicious prompt that coerces the language model into executing arbitrary JavaScript in the context of the web page.   This is indicative of vulnerabilities in systems utilizing LLMs, specifically in how input (prompts) are processed, leading to potential Cross-Site Scripting (XSS) attacks. "
CVE-2024-6959,"A vulnerability in the parisneo/lollms-webui version 9.8 allows for a Denial of Service (DoS) attack when uploading an improperly formatted file.   This is relevant because it affects a system designed for LLM interaction, leading to service downtime."
CVE-2024-7473,"An IDOR vulnerability in lunary-ai's 'Evaluations' function allows users to update other users' prompts by manipulating the 'id' parameter.   This vulnerability compromises the integrity of prompt data, specifically targeting the 'evaluations' aspect of the LLM, making it highly relevant to LLM systems."
CVE-2024-6960,"The H2O machine learning platform's deserialization of Java objects allows for potentially malicious code execution, as no class whitelist is enforced during the process.   This is categorized as type C because it strongly relates to LLMs through the use of machine learning models while not exclusively targeting components directly relevant to LLMs, as indicated by ""potentially allowing execution of malicious code."" "
CVE-2024-5935,"A Cross-Site Request Forgery (CSRF) vulnerability in the imartinez/privategpt application allows attackers to delete all uploaded files on the server, leading to potential data loss and service disruption.   This is relevant to LLMs as privategpt is specifically designed to utilize large language models, and the vulnerability can compromise the integrity and availability of user data."
CVE-2024-6723,"The vulnerability in the AI Engine WordPress plugin up to version 2.4.8 allows SQL injection attacks through unsanitized parameters used in SQL statements, which can be exploited by admin users viewing chatbot interactions.   This is relevant to LLMs as it potentially compromises the integrity of the data managed by AI systems, directly affecting their functionality and output quality—evident from ""leads to a SQL injection exploitable by admin users."""
CVE-2024-6985,A path traversal vulnerability in the api open_personality_folder of parisneo/lollms-webui allows unauthorized access to local files.   This could lead to unauthorized information disclosure since the attacker can exploit improper sanitization of the personality_folder parameter.
CVE-2024-8768,"A flaw in the vLLM library causes the completions API server to crash when an empty prompt is requested, leading to denial of service.   This vulnerability directly impacts the vLLM API, which is crucial for large language model interactions.  "
CVE-2024-7807,"A vulnerability exists in the ChuanhuChatGPT system, allowing for a Denial of Service attack through excessive character uploads that exhaust system resources.   This impact is critical as it renders the service inaccessible, disrupting operations, and is indicated by ""Denial of Service (DOS) attack"" and ""uncontrolled resource consumption""."
CVE-2024-6846,"The vulnerability in the ""Chatbot with ChatGPT WordPress"" plugin allows unauthenticated users to purge error and chat logs due to improper access control on some REST routes.   This flaw specifically impacts the components used to manage chat history and error logs within an LLM-related system, indicating a potential data leakage risk."
CVE-2024-7713,"The vulnerability CVE-2024-7713 involves an unauthenticated OpenAI API Key disclosure in the AI Chatbot with ChatGPT plugin for WordPress prior to version 2.1.0.   This exposes sensitive information that could be exploited for unauthorized access, as stated, ""discloses the Open AI API Key, allowing unauthenticated users to obtain it.""  "
CVE-2024-8309,"A vulnerability in the langchain-ai/langchain system allows for SQL injection through the GraphCypherQAChain class, impacting data integrity and security.   This is relevant because the exploitation of this vulnerability can lead to unauthorized data manipulation within a system used for large language model applications."
CVE-2024-7042,"A vulnerability in the GraphCypherQAChain class of langchain-ai/langchainjs allows for prompt injection leading to SQL injection, impacting user data and security.   This highlights a specific weakness in a component used for interacting with LLM queries, as it can lead to unauthorized manipulation and severe security breaches."
CVE-2024-7962,"An arbitrary file read vulnerability in gaizhenbiao/chuanhuchatgpt due to insufficient validation when loading prompt template files can lead to information leakage.   This is strongly relevant to LLM systems, as it mentions ""loading prompt template files"" which are core components used in LLM interactions."
CVE-2024-8143,"In the latest version of the app gaizhenbiao/chuanhuchatgpt, a vulnerability allows authenticated users to access the private chat histories of other users via the /file endpoint.   This is relevant because it exposes sensitive user data, potentially leading to data leaks and privacy violations, affecting the integrity of user interactions in the LLM context."
CVE-2024-7783,"The vulnerability in mintplex-labs/anything-llm involves improper storage of a password within a JWT used as a bearer token, revealing sensitive information when decoded.   This is strongly relevant to LLMs as it impacts the management of sensitive information in LLM-related applications, highlighting risks such as ""sensitive information, specifically a password, is improperly stored.""  "
CVE-2024-7557,"A vulnerability in OpenShift AI allows for authentication bypass and privilege escalation across AI models within the same namespace through exposed ServiceAccount tokens.   This issue highlights the potential for unauthorized access to sensitive resources within LLM environments, as it states, ""credentials from one model can be used to access other models and APIs."""
CVE-2024-8939,"A vulnerability in the ilab model serve component of the vllm JSON web API allows for Denial of Service (DoS) attacks due to improper handling of the best_of parameter.   This issue relates strongly to LLM operational integrity as it affects API responsiveness, preventing legitimate access by consuming excessive resources, evidenced by phrases like ""makes the API unresponsive."""
CVE-2024-7714,"The AI ChatBot with ChatGPT and Content Generator by AYS plugin for WordPress is vulnerable due to improper access controls, allowing unauthenticated users to disconnect it from OpenAI.   This vulnerability enables unauthorized actions such as 'ays_chatgpt_disconnect', which directly impacts the LLM's operational integrity in this specific use case.  "
CVE-2025-23042,"Gradio's Access Control List (ACL) for file paths can be bypassed due to improper authorization, allowing unauthorized access to sensitive files on the system.   This vulnerability is relevant to LLM contexts since Gradio facilitates building web applications for ML models, and unauthorized access diminishes the security of these deployments."
CVE-2025-25183,"vLLM, a high-throughput inference engine for LLMs, is vulnerable to predictable hash collisions due to changes in Python's hash function, leading to potential cache spoofing.   This vulnerability allows attackers to manipulate the prefix cache, leading to interference with responses, evidenced by ""maliciously constructed statements can lead to hash collisions, resulting in cache reuse.""  "
CVE-2025-24357,"vLLM is a library for LLM inference that has a vulnerability in the hf_model_weights_iterator which can allow for remote code execution (RCE) through the insecure deserialization of model weights.   The vulnerability arises from using `torch.load` without proper validation of data, leading to possible execution of arbitrary code during unpickling."
CVE-2024-4897,"The vulnerability allows remote code execution in the `parisneo/lollms-webui` system due to insecure handling of model files in the 'binding_zoo' feature.   This is relevant to LLMs because it directly involves the management of model files, which are critical in LLM operations, as indicated by ""allow attackers to upload and interact with a malicious model file.""  "
CVE-2024-56516,"free-one-api, which allows access to LLM reverse engineering libraries, uses MD5 for password storage, making user credentials vulnerable to attacks.   This is pertinent as MD5 is known to be insecure, with the advisory noting ""MD5 is a cryptographically broken hashing algorithm."""
CVE-2024-6961,"RAIL documents, an XML-based format used by Guardrails AI to enforce checks on LLM outputs, are vulnerable to XXE attacks, potentially leaking internal data.   This is relevant as it directly affects a component of LLM systems, where the exploitation of XML can compromise data integrity as noted in the description ""vulnerable to XXE.""  "
CVE-2024-6035,"Stored XSS vulnerability in the gaizhenbiao/chuanhuchatgpt system allows attackers to inject malicious scripts into chat history files, potentially compromising user security.   This issue is relevant to LLMs as it pertains to user interactions with chatbot systems, which may involve sensitive data and trust in the model's responses."
